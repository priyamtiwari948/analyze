# Data Processing and CI/CD Pipeline

This project demonstrates a robust data processing pipeline using Python with Pandas,
automated with GitHub Actions, and deployed using GitHub Pages.

## Project Structure

*   `execute.py`: Python script for processing data from `data.xlsx` (or `data.csv`).
*   `data.xlsx`: Initial Excel data file (input).
*   `data.csv`: CSV version of `data.xlsx`, generated during CI.
*   `.github/workflows/ci.yml`: GitHub Actions workflow for CI/CD.
*   `index.html`: A simple, responsive static site to present the project and link to results.
*   `result.json`: JSON output generated by `execute.py`, published via GitHub Pages (not committed to repo).

## Setup and Local Execution

### Prerequisites

*   Python 3.11+
*   pip (Python package installer)

### Installation

1.  Clone this repository:
    ```bash
    git clone https://github.com/your-username/your-repo-name.git
    cd your-repo-name
    ```
2.  Create a virtual environment (recommended):
    ```bash
    python -m venv venv
    source venv/bin/activate # On Windows: `venv\Scripts\activate`
    ```
3.  Install dependencies:
    ```bash
    pip install pandas==2.3.0 openpyxl ruff
    ```

### Running the Script Locally

1.  **Prepare `data.xlsx`**: Ensure `data.xlsx` is in the project root. A sample `data.xlsx` would look like:

    | ID | Product     | Region    | Sales | Quantity |
    |----|-------------|-----------|-------|----------|
    | 1  | Laptop      | North     | 1200  | 1        |
    | 2  | Mouse       | North     | 25    | 5        |
    | 3  | Keyboard    | South     | 75    | 2        |
    | 4  | Monitor     | East      | 300   | 1        |
    | 5  | Laptop      | West      | 1100  | 1        |
    | 6  | Headphones  | South     | 150   | 3        |
    | 7  | Mouse       | East      | N/A   | 10       |
    | 8  | Keyboard    | North     | 80    | 1        |
    | 9  | Monitor     | West      | 320   | 1        |
    | 10 | Docking Sta | South     | 200   | 1        |
    | 11 | Laptop      | East      | invalid_sales | 1        |

2.  **Convert to CSV (Optional, but useful for testing the `execute.py` with CSV input)**:
    ```bash
    python -c "import pandas as pd; df = pd.read_excel('data.xlsx'); df.to_csv('data.csv', index=False)"
    ```

3.  **Execute the script**:
    ```bash
    python execute.py data.csv > result.json
    ```
    This will generate `result.json` in your project root.

### Linting

Run Ruff to check for code quality and style issues:
```bash
ruff check .
```

## `execute.py` - Error Fix Details

The `execute.py` script is designed to process sales data, specifically calculating total sales per region.
A non-trivial error in the original version would arise if the `Sales` column contained
non-numeric values (e.g., text like "N/A", "invalid_sales", or empty cells). Such entries would cause
Pandas numeric operations (like `sum()`) to fail with `TypeError` or `ValueError`.

**The Fix:**

The updated `execute.py` now includes a robust handling mechanism for the `Sales` column:
```python
df['Sales'] = pd.to_numeric(df['Sales'], errors='coerce')
df = df.dropna(subset=['Sales'])
```
1.  `pd.to_numeric(df['Sales'], errors='coerce')`: This attempts to convert the `Sales` column to a numeric type. If any value cannot be converted (e.g., "N/A", "invalid_sales"), it will be replaced with `NaN` (Not a Number) instead of raising an error.
2.  `df.dropna(subset=['Sales'])`: After coercing non-numeric values to `NaN`, this step removes any rows where the `Sales` value is `NaN`, ensuring that all subsequent numeric operations are performed on valid numbers.

This fix makes the script resilient to malformed data in the `Sales` column, preventing crashes and ensuring reliable data aggregation.

## GitHub Actions CI/CD Workflow (`.github/workflows/ci.yml`)

This project includes a GitHub Actions workflow that automates the following steps on every push to `main` and on pull requests:

1.  **Checkout Code**: Retrieves the repository's content.
2.  **Setup Python 3.11**: Configures the environment with Python 3.11.
3.  **Install Dependencies**: Installs `pandas`, `openpyxl`, and `ruff`.
4.  **Run Ruff Linter**: Checks the Python code for style and quality issues. Results are shown in the CI log.
5.  **Convert `data.xlsx` to `data.csv`**: Uses Pandas to convert the initial Excel file into a CSV format.
6.  **Execute Python Script**: Runs `execute.py` with `data.csv` as input and redirects its output to `result.json`.
7.  **Setup Pages & Upload Artifact**: Configures GitHub Pages and uploads `result.json` as a deployable artifact.
8.  **Deploy to GitHub Pages**: Publishes `result.json` to your repository's GitHub Pages.

### Accessing Results

After a successful CI/CD run, `result.json` will be accessible via GitHub Pages.
You can find the link in your repository settings under "Pages" or by navigating to:

`https://<your-username>.github.io/<your-repo-name>/result.json`

(Replace `<your-username>` and `<your-repo-name>` with your actual GitHub details.)

The `index.html` page also provides a direct link to this published `result.json`.

## License

This project is licensed under the MIT License. See the `LICENSE` file for details.